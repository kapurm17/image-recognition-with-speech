{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import cv2\n",
    "#from time import sleep\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import os\n",
    "from threading import Thread\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threaded class for performance improvement\n",
    "class VideoStream:\n",
    "\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "                # Return the latest frame\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"video_capture = cv2.VideoCapture(0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "    def __init__(self,label_lookup_path=None,uid_lookup_path=None):\n",
    "        if not label_lookup_path:\n",
    "            label_lookup_path = os.path.join(model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "        if not uid_lookup_path:\n",
    "            uid_lookup_path = os.path.join(model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
    "        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "    def load(self, label_lookup_path, uid_lookup_path):\n",
    "\n",
    "        if not tf.gfile.Exists(uid_lookup_path):\n",
    "            tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "        if not tf.gfile.Exists(label_lookup_path):\n",
    "            tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human = {}\n",
    "        p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "        for line in proto_as_ascii_lines:\n",
    "            parsed_items = p.findall(line)\n",
    "            uid = parsed_items[0]\n",
    "            human_string = parsed_items[2]\n",
    "            uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "        node_id_to_uid = {}\n",
    "        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        for line in proto_as_ascii:\n",
    "            if line.startswith('  target_class:'):\n",
    "                target_class = int(line.split(': ')[1])\n",
    "            if line.startswith('  target_class_string:'):\n",
    "                target_class_string = line.split(': ')[1]\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "        node_id_to_name = {}\n",
    "        for key, val in node_id_to_uid.items():\n",
    "            if val not in uid_to_human:\n",
    "                tf.logging.fatal('Failed to locate: %s', val)\n",
    "            name = uid_to_human[val]\n",
    "            node_id_to_name[key] = name\n",
    "\n",
    "        return node_id_to_name\n",
    "\n",
    "    def id_to_string(self, node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]\n",
    "\n",
    "\n",
    "def create_graph():\n",
    "\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "    # Download and extract model tar file\n",
    "    dest_directory = model_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-085829d6f73a>:55: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "maybe_download_and_extract()\n",
    "create_graph()\n",
    "\n",
    "# Variables declarations\n",
    "frame_count=0\n",
    "score=0\n",
    "start = time.time()\n",
    "pygame.mixer.init()\n",
    "pred=0\n",
    "last=0\n",
    "human_str=None\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color=(255,255,255)\n",
    "\n",
    "# Init video stream\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "# Start tensroflow session\n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "\n",
    "    while True:\n",
    "        frame = vs.read()\n",
    "        frame_count+=1\n",
    "\n",
    "        # Only run every 5 frames\n",
    "        if frame_count%5==0:\n",
    "\n",
    "            # Save the image as the fist layer of inception is a DecodeJpeg\n",
    "            cv2.imwrite(\"current_frame.jpg\",frame)\n",
    "\n",
    "            image_data = tf.gfile.FastGFile(\"./current_frame.jpg\", 'rb').read()\n",
    "            predictions=sess.run(softmax_tensor,{'DecodeJpeg/contents:0':image_data})\n",
    "\n",
    "            predictions = np.squeeze(predictions)\n",
    "            node_lookup = NodeLookup()\n",
    "\n",
    "            # change n_pred for more predictions\n",
    "            n_pred=1\n",
    "            top_k = predictions.argsort()[-n_pred:][::-1]\n",
    "            for node_id in top_k:\n",
    "                human_str_n = node_lookup.id_to_string(node_id)\n",
    "                score = predictions[node_id]\n",
    "            if score>.5:\n",
    "                # Some manual corrections\n",
    "                if human_str_n==\"syringe\" or human_str_n==\"screwdriver\" :\n",
    "                    human_str_n=\"Pen\"\n",
    "                if human_str_n==\"stethoscope\":\n",
    "                    human_str_n=\"Headphones\"\n",
    "                if human_str_n==\"spatula\":\n",
    "                    human_str_n=\"fork\"\n",
    "                if human_str_n==\"iPod\":\n",
    "                    human_str_n=\"Smartphone\"\n",
    "                human_str=human_str_n\n",
    "\n",
    "                lst=human_str.split()\n",
    "                human_str=\" \".join(lst[0:2])\n",
    "                human_str_filename=str(lst[0])\n",
    "\n",
    "            current= time.time()\n",
    "            fps=frame_count/(current-start)\n",
    "\n",
    "        # Speech module\n",
    "        if last>40 and not pygame.mixer.music.get_busy() and human_str==human_str_n:\n",
    "            pred+=1\n",
    "            name=human_str_filename+\".mp3\"\n",
    "\n",
    "            # Only get from google if we dont have it\n",
    "            if not os.path.isfile(name):\n",
    "                tts = gTTS(text=\"Wow! A \"+human_str, lang='en')\n",
    "                tts.save(name)\n",
    "\n",
    "            last=0\n",
    "            pygame.mixer.music.load(name)\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "        # Show info during some time              \n",
    "        if last<40 and frame_count>10:\n",
    "            # Change the text position depending on your camera resolution\n",
    "            cv2.putText(frame,human_str, (20,400),font, 1, font_color)\n",
    "            cv2.putText(frame,str(np.round(score,2))+\"%\",(20,440),font,1,font_color)\n",
    "\n",
    "        if frame_count>20:\n",
    "            fps_text=\"fps: \"+str(np.round(fps,2))\n",
    "            cv2.putText(frame, fps_text, (460,460), font, 1, font_color)\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        last+=1\n",
    "\n",
    "\n",
    "        # if the 'q' key is pressed, stop the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "# cleanup everything\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()     \n",
    "sess.close()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
